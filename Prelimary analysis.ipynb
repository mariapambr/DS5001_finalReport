{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c4b728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_9512\\3178743543.py:24: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import re\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "from scipy.linalg import eigh, norm\n",
    "import plotly_express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from gensim.models import word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "epub_dir = 'epubs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bac78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/maria/OneDrive/Desktop/UVA Data Science/ETA/Final_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0018abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eliot = pd.read_csv('145.txt', sep='\\t', header = None, names=['text'])\n",
    "df_shelley = pd.read_csv('18247.txt', sep='\\t', header = None, names=['text'])\n",
    "df_woolf = pd.read_csv('144.txt', sep='\\t', header = None, names=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d908522",
   "metadata": {},
   "source": [
    "**Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79dac4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chaps = \"First|Second|Third|Fourth|Fifth|Sixth\"\n",
    "chap_pats = {\n",
    "145: {\n",
    "    'start_line': 24,\n",
    "    'end_line': 28115,\n",
    "    'chapter': re.compile('^\\s*CHAPTER\\s+{}.\\s*$'.format(roman))\n",
    "    },\n",
    "18247: {\n",
    "    'start_line': 22,\n",
    "    'end_line': 15117,\n",
    "    'chapter': re.compile('^\\s*CHAPTER\\s+{}.\\s*$'.format(roman))\n",
    "    },\n",
    "144: {\n",
    "    'start_line': 19,\n",
    "    'end_line': 12223,\n",
    "    'chapter': re.compile('^\\s*CHAPTER\\s+{}.\\s*$'.format(roman))\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db454d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_epubs(epub_list, chap_pats, OHCO=OHCO):\n",
    "    my_lib = []\n",
    "    my_doc = []\n",
    "\n",
    "    for epub_file in epub_list:\n",
    "        # Get PG ID from filename\n",
    "        book_id = int(epub_file.split('.')[0])\n",
    "        print(\"BOOK ID\", book_id)\n",
    "\n",
    "        # Import file as lines\n",
    "        lines = open(epub_file, 'r', encoding='utf-8-sig').readlines()\n",
    "        df = pd.DataFrame(lines, columns=['line_str'])\n",
    "        df.index.name = 'line_num'\n",
    "        df.line_str = df.line_str.str.strip()\n",
    "        df['book_id'] = book_id\n",
    "\n",
    "        # FIX CHARACTERS TO IMPROVE TOKENIZATION\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "\n",
    "        # Get book title and put into LIB table -- note problems, though\n",
    "        book_title = re.sub(r\"The Project Gutenberg eBook( of|,) \", \"\", df.loc[0].line_str, flags=re.IGNORECASE)\n",
    "        book_title = re.sub(r\"Project Gutenberg's \", \"\", book_title, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove cruft\n",
    "        a = chap_pats[book_id]['start_line'] - 1\n",
    "        b = chap_pats[book_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]\n",
    "\n",
    "        # Chunk by chapter\n",
    "        chap_lines = df.line_str.str.match(chap_pats[book_id]['chapter'])\n",
    "        chap_nums = [i+1 for i in range(df.loc[chap_lines].shape[0])]\n",
    "        df.loc[chap_lines, 'chap_num'] = chap_nums\n",
    "        df.chap_num = df.chap_num.ffill()\n",
    "\n",
    "        # Clean up\n",
    "        df = df[~df.chap_num.isna()] # Remove chapter heading lines\n",
    "        df = df.loc[~chap_lines] # Remove everything before Chapter 1\n",
    "        df['chap_num'] = df['chap_num'].astype('int')\n",
    "\n",
    "        # Group -- Note that we exclude the book level in the OHCO at this point\n",
    "        df = df.groupby(OHCO[1:2]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "\n",
    "        # Split into paragraphs\n",
    "        df = df['line_str'].astype(str).str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:3] # MAY NOT BE NECESSARY UNTIL THE END\n",
    "        df['para_str'] = df['para_str'].astype(str).str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].astype(str).str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "\n",
    "        # Set index\n",
    "        df['book_id'] = book_id\n",
    "        df = df.reset_index().set_index(OHCO[:3])\n",
    "\n",
    "        # Register\n",
    "        my_lib.append((book_id, book_title, epub_file))\n",
    "        my_doc.append(df)\n",
    "\n",
    "    docs = pd.concat(my_doc)\n",
    "    library = pd.DataFrame(my_lib, columns=['book_id', 'book_title', 'book_file']).set_index('book_id')\n",
    "    print(\"Done.\")\n",
    "    return library, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb454d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 144\n",
      "BOOK ID 145\n",
      "BOOK ID 18247\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_9512\\4268693771.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['para_str'] = df['para_str'].astype(str).str.replace(r'\\n', ' ').str.strip()\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_9512\\4268693771.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['para_str'] = df['para_str'].astype(str).str.replace(r'\\n', ' ').str.strip()\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_9512\\4268693771.py:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['para_str'] = df['para_str'].astype(str).str.replace(r'\\n', ' ').str.strip()\n"
     ]
    }
   ],
   "source": [
    "epubs = [epub for epub in sorted(glob('*.txt'))]\n",
    "LIB, DOC = acquire_epubs(epubs, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ff9d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>92</th>\n",
       "      <th>40</th>\n",
       "      <td>“Not high - flown enough?”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">144</th>\n",
       "      <th>34</th>\n",
       "      <th>161</th>\n",
       "      <td>“They have such excellent biscuits here,” she ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>111</th>\n",
       "      <td>“I’m an old - fashioned father.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <th>37</th>\n",
       "      <td>The clock here struck twelve instead of eleven.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>123</th>\n",
       "      <td>“No, no,” laughed Willoughby, “the monsters of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>116</th>\n",
       "      <th>31</th>\n",
       "      <td>When he was gone, Dorothea’s tears gushed fort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">144</th>\n",
       "      <th>33</th>\n",
       "      <th>35</th>\n",
       "      <td>Creeping on, they found that the next window r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>9</th>\n",
       "      <td>“A grand fellow, Shakespeare,” he said, replac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">145</th>\n",
       "      <th>94</th>\n",
       "      <th>8</th>\n",
       "      <td>“What is the matter with Casaubon? I see no ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <th>17</th>\n",
       "      <td>Mr. Farebrother noticed that Lydgate seemed bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    para_str\n",
       "book_id chap_num para_num                                                   \n",
       "145     92       40                               “Not high - flown enough?”\n",
       "144     34       161       “They have such excellent biscuits here,” she ...\n",
       "        27       111                        “I’m an old - fashioned father.”\n",
       "        46       37          The clock here struck twelve instead of eleven.\n",
       "        27       123       “No, no,” laughed Willoughby, “the monsters of...\n",
       "145     116      31        When he was gone, Dorothea’s tears gushed fort...\n",
       "144     33       35        Creeping on, they found that the next window r...\n",
       "        30       9         “A grand fellow, Shakespeare,” he said, replac...\n",
       "145     94       8         “What is the matter with Casaubon? I see no ha...\n",
       "        149      17        Mr. Farebrother noticed that Lydgate seemed bo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0754777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split paragraphs into sentences\n",
    "dfs = DOC['para_str'].str.split(r'[.?!;:\"]+', expand=True).stack()\\\n",
    "    .to_frame().rename(columns={0:'sent_str'})\n",
    "\n",
    "dfs.index.names = OHCO[:4]\n",
    "\n",
    "dfs = dfs[~dfs['sent_str'].str.match(r'^\\s*$')] # Remove empty paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37fff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">144</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">27</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>As</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>streets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">18247</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">58</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">13</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>let</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578422 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str\n",
       "book_id chap_num para_num sent_num token_num          \n",
       "144     27       1        0        0           CHAPTER\n",
       "                                   1                 I\n",
       "                 2        0        0                As\n",
       "                                   1               the\n",
       "                                   2           streets\n",
       "...                                                ...\n",
       "18247   58       13       3        1               let\n",
       "                                   2                me\n",
       "                                   3             dwell\n",
       "                                   4                on\n",
       "                                   5              your\n",
       "\n",
       "[578422 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into tokens\n",
    "dft = dfs['sent_str'].str.split(r\"[\\s',-]+\", expand=True).stack()\\\n",
    "    .to_frame().rename(columns={0:'token_str'})\n",
    "    \n",
    "dft.index.names = OHCO[:5]\n",
    "dft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74b4eb",
   "metadata": {},
   "source": [
    "**Tokenize and Annotate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868ca9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x))) # Discards stuff in between\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "668540bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(DOC, ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d8411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN.to_csv(\"TOKEN_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5c4f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">144</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">27</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(CHAPTER, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(As, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>As</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(streets, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>streets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str\n",
       "book_id chap_num para_num sent_num token_num                               \n",
       "144     27       1        0        0           (CHAPTER, NN)   NN   CHAPTER\n",
       "                                   1                (I, PRP)  PRP         I\n",
       "                 2        0        0                (As, IN)   IN        As\n",
       "                                   1               (the, DT)   DT       the\n",
       "                                   2          (streets, NNS)  NNS   streets"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b5d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TOKEN[TOKEN.pos.str.match('^JJ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4d36e",
   "metadata": {},
   "source": [
    "**Extract vocabulary from the Token table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c02b1945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_10016\\1858674674.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')\n"
     ]
    }
   ],
   "source": [
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "539a9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKEN.term_str.value_counts()\\\n",
    "    .to_frame()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')\n",
    "\n",
    "# add stopwords to vocab\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0316b11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>his</td>\n",
       "      <td>5663</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>been</td>\n",
       "      <td>1564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20920</th>\n",
       "      <td>we</td>\n",
       "      <td>1695</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>below</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>have</td>\n",
       "      <td>2458</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>y</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>by</td>\n",
       "      <td>2664</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16235</th>\n",
       "      <td>s</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21478</th>\n",
       "      <td>yourself</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16960</th>\n",
       "      <td>should</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_str     n  num  stop\n",
       "term_id                           \n",
       "9009          his  5663    0     1\n",
       "1703         been  1564    0     1\n",
       "20920          we  1695    0     1\n",
       "1789        below    33    0     1\n",
       "8764         have  2458    0     1\n",
       "21423           y    10    0     1\n",
       "2531           by  2664    0     1\n",
       "16235           s     3    0     1\n",
       "21478    yourself    86    0     1\n",
       "16960      should  1024    0     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db96f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding stems to vocab\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.term_str.apply(stemmer1.stem)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.term_str.apply(stemmer2.stem)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.term_str.apply(stemmer3.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12ad569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>The Voyage Out, by Virginia Woolf</td>\n",
       "      <td>144.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Middlemarch, by George Eliot</td>\n",
       "      <td>145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>The Last Man, by Mary Wollstonecraft Shelley</td>\n",
       "      <td>18247.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_title  book_file\n",
       "book_id                                                         \n",
       "144                 The Voyage Out, by Virginia Woolf    144.txt\n",
       "145                      Middlemarch, by George Eliot    145.txt\n",
       "18247    The Last Man, by Mary Wollstonecraft Shelley  18247.txt"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c1b1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#DOC.to_csv(\"DOC.csv\")\n",
    "LIB.to_csv(\"LIB_final.csv\")\n",
    "#VOCAB.to_csv(\"VOCAB.csv\")\n",
    "#TOKEN.to_csv(\"TOKEN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a6a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = pd.read_csv('VOCAB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "895332b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>7301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1348</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1348</td>\n",
       "      <td>1348</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1580</td>\n",
       "      <td>1580</td>\n",
       "      <td>1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1660</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1660</td>\n",
       "      <td>1660</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1790</td>\n",
       "      <td>1790</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1818</td>\n",
       "      <td>1818</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1822</td>\n",
       "      <td>1822</td>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1825</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1826</td>\n",
       "      <td>1826</td>\n",
       "      <td>1826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str     n  num  stop stem_porter stem_snowball stem_lancaster\n",
       "term_id                                                                   \n",
       "0                 7301    0     0                                         \n",
       "1              1     2    1     0           1             1              1\n",
       "2             10     2    1     0          10            10             10\n",
       "3             11     1    1     0          11            11             11\n",
       "4            112     1    1     0         112           112            112\n",
       "5             12     2    1     0          12            12             12\n",
       "6             13     1    1     0          13            13             13\n",
       "7           1348     1    1     0        1348          1348           1348\n",
       "8             14     2    1     0          14            14             14\n",
       "9             15     1    1     0          15            15             15\n",
       "10          1580     1    1     0        1580          1580           1580\n",
       "11            16     2    1     0          16            16             16\n",
       "12          1660     1    1     0        1660          1660           1660\n",
       "13            17     2    1     0          17            17             17\n",
       "14          1790     1    1     0        1790          1790           1790\n",
       "15            18     2    1     0          18            18             18\n",
       "16          1818     1    1     0        1818          1818           1818\n",
       "17          1822     1    1     0        1822          1822           1822\n",
       "18          1825     1    1     0        1825          1825           1825\n",
       "19          1826     1    1     0        1826          1826           1826"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60e79b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most frequent POS tag associated with a specific term\n",
    "def get_POS_Count(row):\n",
    "    term = row['term_str']\n",
    "\n",
    "    return TOKEN[TOKEN['term_str']== term].value_counts('pos').idxmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fe72b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_POS_Count(row):\n",
    "    term = row['term_str']\n",
    "    filtered_tokens = TOKEN[TOKEN['term_str'] == term]\n",
    "    if not filtered_tokens.empty:\n",
    "        return filtered_tokens['pos'].value_counts().idxmax()\n",
    "    else:\n",
    "        return None  # Handle the case where the sequence is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "148c9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['pos_max'] = VOCAB.apply(get_POS_Count, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09f101a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "      <th>pos_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>disreputable</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disreput</td>\n",
       "      <td>disreput</td>\n",
       "      <td>disreput</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8542</th>\n",
       "      <td>guido</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>guido</td>\n",
       "      <td>guido</td>\n",
       "      <td>guido</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>preferable</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prefer</td>\n",
       "      <td>prefer</td>\n",
       "      <td>pref</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>canoes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cano</td>\n",
       "      <td>cano</td>\n",
       "      <td>cano</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>persuasively</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>persuas</td>\n",
       "      <td>persuas</td>\n",
       "      <td>persuas</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14028</th>\n",
       "      <td>pleasure</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pleasur</td>\n",
       "      <td>pleasur</td>\n",
       "      <td>pleas</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>rap</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>cornish</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cornish</td>\n",
       "      <td>cornish</td>\n",
       "      <td>corn</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13625</th>\n",
       "      <td>perfumed</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>perfum</td>\n",
       "      <td>perfum</td>\n",
       "      <td>perfum</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>physicist</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>physicist</td>\n",
       "      <td>physicist</td>\n",
       "      <td>phys</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str    n  num  stop stem_porter stem_snowball  \\\n",
       "term_id                                                           \n",
       "5507     disreputable    3    0     0    disreput      disreput   \n",
       "8542            guido    1    0     0       guido         guido   \n",
       "14356      preferable    3    0     0      prefer        prefer   \n",
       "2642           canoes    1    0     0        cano          cano   \n",
       "13698    persuasively    2    0     0     persuas       persuas   \n",
       "14028        pleasure  133    0     0     pleasur       pleasur   \n",
       "15111             rap    2    0     0         rap           rap   \n",
       "4120          cornish    1    0     0     cornish       cornish   \n",
       "13625        perfumed    2    0     0      perfum        perfum   \n",
       "13797       physicist    1    0     0   physicist     physicist   \n",
       "\n",
       "        stem_lancaster pos_max  \n",
       "term_id                         \n",
       "5507          disreput      JJ  \n",
       "8542             guido     NNP  \n",
       "14356             pref      JJ  \n",
       "2642              cano     NNS  \n",
       "13698          persuas      NN  \n",
       "14028            pleas      NN  \n",
       "15111              rap      NN  \n",
       "4120              corn     NNP  \n",
       "13625           perfum     VBN  \n",
       "13797             phys      NN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1167c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term rank to VOCAB\n",
    "if 'term_rank' not in VOCAB.columns:\n",
    "    VOCAB = VOCAB.sort_values('n', ascending=False).reset_index()\n",
    "    VOCAB.index.name = 'term_rank'\n",
    "    VOCAB = VOCAB.reset_index()\n",
    "    VOCAB = VOCAB.set_index('term_id')\n",
    "    VOCAB['term_rank'] = VOCAB['term_rank'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49083ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>term_rank2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18871</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>26880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12845</th>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>17206</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>16460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19145</th>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>16159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>11162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank term_str      n  num  stop stem_porter stem_snowball  \\\n",
       "term_id                                                                   \n",
       "18871            1      the  26880    0     1         the           the   \n",
       "12845            2       of  17206    0     1          of            of   \n",
       "764              3      and  16460    0     1         and           and   \n",
       "19145            4       to  16159    0     1          to            to   \n",
       "65               5        a  11162    0     1           a             a   \n",
       "\n",
       "        stem_lancaster pos_max  term_rank2  \n",
       "term_id                                     \n",
       "18871              the      DT           1  \n",
       "12845               of      IN           2  \n",
       "764                and      CC           3  \n",
       "19145               to      TO           4  \n",
       "65                   a      DT           5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rank = VOCAB.n.value_counts()\\\n",
    "    .sort_index(ascending=False).reset_index().reset_index()\\\n",
    "    .rename(columns={'level_0':'term_rank2', 'index':'n', 'n':'nn'})\\\n",
    "    .set_index('n')\n",
    "VOCAB['term_rank2'] = VOCAB.n.map(new_rank.term_rank2) + 1\n",
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c8bcc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">144</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">27</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(CHAPTER, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>CHAPTER</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(As, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>As</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(streets, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>streets</td>\n",
       "      <td>streets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_num para_num sent_num token_num                                  \n",
       "144     27       1        0        0           (CHAPTER, NN)   NN   CHAPTER   \n",
       "                                   1                (I, PRP)  PRP         I   \n",
       "                 2        0        0                (As, IN)   IN        As   \n",
       "                                   1               (the, DT)   DT       the   \n",
       "                                   2          (streets, NNS)  NNS   streets   \n",
       "\n",
       "                                             term_str  \n",
       "book_id chap_num para_num sent_num token_num           \n",
       "144     27       1        0        0          chapter  \n",
       "                                   1                i  \n",
       "                 2        0        0               as  \n",
       "                                   1              the  \n",
       "                                   2          streets  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e9659c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv(\"VOCAB_final.csv\")\n",
    "TOKEN.to_csv(\"TOKEN_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penocchio",
   "language": "python",
   "name": "penocchio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
